package com.mhh.cloud.kafka.consumer;

import kafka.api.FetchRequest;
import kafka.api.FetchRequestBuilder;
import kafka.api.PartitionOffsetRequestInfo;
import kafka.common.ErrorMapping;
import kafka.common.TopicAndPartition;
import kafka.javaapi.*;
import kafka.javaapi.consumer.SimpleConsumer;
import kafka.message.MessageAndOffset;

import java.nio.ByteBuffer;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;

public class TestConsumer {
	public static void main(String args[])
	{
		TestConsumer example = new TestConsumer();
		long maxReads = 100;
		String topic = "mhh_page_visits";
		int partition = 1;
		List<String> seeds = new ArrayList<String>();
		seeds.add("localhost");
		int port = Integer.parseInt("9092");
		
		try
		{
			example.run(maxReads, topic, partition, seeds, port);
		} catch(Exception e)
		{
			System.out.println("Oops:" + e);
			e.printStackTrace();			
		}
		
	}
	
	private List<String> m_replicaBrokers = new ArrayList<String>();
	
	public TestConsumer(){
		m_replicaBrokers = new ArrayList<String>();		
	}
	
	public void run(long a_maxReads, String a_topic, int a_partition, List<String> a_seedBrokers, int a_port)throws Exception
	{
		PartitionMetadata metadata = findLeader(a_seedBrokers, a_port, a_topic, a_partition);
		if(metadata == null)
		{
			System.out.println("Can't find metadata for Topic and Partition.existing");
			return;
		}
		if(metadata.leader() == null)
		{
			System.out.println("can't find leader for topic and partition.existing");
			return;			
		}
		
		String leadBroker = metadata.leader().host();
		String clientName = "Client_" + a_topic + "_" + a_partition;
		
		SimpleConsumer consumer = new SimpleConsumer(leadBroker, a_port, 100000, 64*1024, clientName);
		long readOffset = getLastOffset(consumer, a_topic, a_partition, kafka.api.OffsetRequest.EarliestTime(), clientName);
	}

}
